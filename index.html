
<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- bulma css template -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <!-- ionicons -->
  <script type="module" src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.js"></script>
  <!-- model viewer -->
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
  <title>
    PromptAvatar: Text-Image Prompted Generation of 3D Animatable Avatars
  </title>
  <link rel="icon" href="icon.ico">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
   
        
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/before_after.css">
  <!-- <link rel="icon" href="./static/images/cameraicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://unpkg.com/imagesloaded@5/imagesloaded.pkgd.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <link rel="stylesheet" href="./static/css/magnify.css">
  <script src="./static/js/jquery.magnify.js"></script>


</head>

<body>

  <style>
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 50%;
  }
    </style>

  <section class="section">
  <div class="container has-text-centered">
    <!-- paper title -->
    <p class="title is-3"> PromptAvatar: Text-Image Prompted Generation of 3D Animatable Avatars </p>
    <p class="title is-4"> Anonymous NeurIPS Submission Paper ID 3741 Supplementary Material </p>
    <!-- publication -->
    <!-- authors -->
    <!-- <p class="title is-5 mt-2"> 
      <a href="https://sites.google.com/view/mingyuan-zhou/home" target="_blank">Mingyuan Zhou*</a><sup>1</sup>, 
      <a href="" target="_blank">Rakib Hyder*</a><sup>1</sup>,
      <a href="" target="_blank">Ziwei Xuan</a><sup>1</sup>
      <a href="http://maple-lab.net/gqi/" target="_blank">Guojun Qi</a><sup>1,2</sup> -->
    <!-- </p> --> 
    <!-- affiliations -->
    <!-- <p class="subtitle is-5">   
      <th><sup>1</sup>OPPO Seattle Research Center, USA </th>
      <th><sup>2</sup>Westlake University, China </th>
      <th><sup>*</sup> Equal contributions</th>
    </p> -->


    <!-- other links -->
    <!-- <div class="is-flex is-justify-content-center">
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://arxiv.org/abs/2401.11078" role="button" target="_blank"> <span class="icon"> <ion-icon name="document-outline"></ion-icon> </span> <span> Arxiv </span>  </a> 
      </span>
      <span class="icon-text mx-1">
        <a class="button is-dark" href=" " role="button" target="_blank"> <span class="icon"> <ion-icon name="logo-github"></ion-icon> </span> <span> Code </span> </a> 
      </span>
    </div> -->
    <br>
    <img class="summary-img" src="Imgs/fig1.png" style="width:100%;">
    <!-- <video muted controls autoplay loop> <source src="animations/ani_7.mp4" type="video/mp4"> </video>  -->
    <!--video  width="100%" loop autoplay muted-->
      <!--source src="animations/open.mp4" type="video/mp4"-->
    <!--/video-->

    <!-- <h1 style="text-align:center"><em> UltrAvatar. Our method takes a text prompt or a single image as input to generate realistic and animatable 3D Avatars with PBR textures, compatible with various rendering engines.</em></h3> -->
  </div>

  <!-- main container -->
  <div class="container">

    <!-- abstract -->
    <p class="title is-3 mt-5 has-text-centered"> Abstract </p>
    <p class="content is-size-6 has-text-left">
      Recently, creating realistic and animatable 3D avatars guided by text or image prompts attracts widespread attention. 
Current text-to-avatar methods lack support for fine-grained text prompts and diversity, largely due to the absence of datasets that do not have detailed text descriptions of 3D facial information (texture and geometry). On the other hand, image-to-avatar methods typically involve acquiring 3D facial data from the real world using specialized equipment and using generative models to establish relationships between images and 3D faces. However, such data is costly and scarce, leading to limited model generalization capabilities. Furthermore, the text-to-avatar methods primarily utilize the Score Distillation Sampling (SDS) loss or CLIP to establish mappings between text and images or 3D faces, raising concerns about diversity, accuracy, and efficiency. To address these challenges, in this paper, we create a large-scale dataset that has four modalities: fine-grained descriptions of facial attributes, in-the-wild face images, high-quality texture UV-maps, and facial shapes, using images as a medium, leveraging vision-language models and 3D-aware generative adversarial networks (GAN).
The pipeline for creating this dataset is cost-effective and reproducible. Based on this dataset, we introduce PromptAvatar which comprises a texture diffusion model, supporting multi-condition guidance from text and image prompts, and a geometry diffusion model guided by text prompts. PromptAvatar can generate an accurate and faithful 3D facial UV-map with its geometry in seconds based on a text or image prompt, compatible with existing rendering engines. PromptAvatar effectively establishes mappings from text or images to 3D faces, and extensive qualitative and quantitative experiments demonstrate the superiority of our method over existing approaches in terms of efficiency, diversity, and quality. Our dataset will be publicly released soon.
    </p>


    <p class="title is-3 mt-5 has-text-centered"> Overview </p>
    <div style="display: flex; justify-content: center;">
      <img class="summary-img" src="Imgs/arch1.png" style="width:70%;">
    </div>
    <br>
    <p class="content is-size-6 has-text-left">
    We first feed a text prompt into a generic diffusion model to produce a face image. Alternatively, the face image can also be directly input into our framework. 
    Second, our diffuse color extraction (DCE) model takes the face image to extract its diffuse colors by eliminating lighting. The diffuse image is then passed to the mesh generator and the edge detector to generate the 3D mesh, camera parameters and the edge image. 
    With these predicted values, the initial texture and the corresponding visibility mask can be created by texture mapping. 
    Lastly, we input the masked initial texture into our authenticity guided texture diffusion model (AGT-DM) to generate the PBR textures. 
    The generated animatable 3D avatars equipped with PBR textures are compatible with various rendering engines for different applications.
   </p>
    <br>
    
    <!-- results (videos) -->
    <p class="title is-3 mt-5 has-text-centered"> Results </p>
      <p class="content has-text-left is-size-6">
        We provide the following video animation results.
      </p>
<br>
      

   

  
  </div>



  <!-- video1 -->
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          
          <div class="active dropdown-toggle">

            <video poster="" id="img_pearl" autoplay controls muted loop playsinline height="100%">
              <source src="videos_gen/leo.mp4"
                      type="video/mp4">
            </video>
          </div>
  
                 
          <div class="active dropdown-toggle">

            <video poster="" id="img_pearl" autoplay controls muted loop playsinline height="100%">
              <source src="videos_gen/brad.mp4"
                      type="video/mp4">
            </video>
          </div>
          
                  
          <div class="active dropdown-toggle">

            <video poster="" id="img_pearl" autoplay controls muted loop playsinline height="100%">
              <source src="videos_gen/our_7.mp4"
                      type="video/mp4">
            </video>
          </div>
          
                  
          <div class="active dropdown-toggle">

            <video poster="" id="img_pearl" autoplay controls muted loop playsinline height="100%">
              <source src="videos_relight/tom.mp4"
                      type="video/mp4">
            </video>
          </div>
          
                  
          <div class="active dropdown-toggle">
     
            <video poster="" id="img_pearl" autoplay controls muted loop playsinline height="100%">
              <source src="videos_relight/will.mp4"
                      type="video/mp4">
            </video>
          </div>
          
                  
          <div class="active dropdown-toggle">
        
            <video poster="" id="img_pearl" autoplay controls muted loop playsinline height="100%">
              <source src="videos_relight/zuc.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div  class="columns is-centered has-text-centered" style="text-align: center;">  
         <p><br/>Our framework can generate 3D avatars through the input of text or image prompts in the paper.</p> </div>
    </div>
  </section>

<br>
<br>

  <!-- video2 -->
<div class="container has-text-centered">
  <div class="content has-text-justified">
    <h3 class="title is-4">Static Camera, Moving Head</h3>
    </div>
  <video muted controls autoplay loop style="width: 80%; height: auto;">
    <source src="animations/ani_7.mp4" type="video/mp4">
  </video>
  <h2 style="text-align:center"><em> Watch videos with a fixed camera capturing the dynamic movements of objects, highlighting their behavior and interactions.</em></h2>
</div>

<br>
<br>

  <!-- video3 -->
<div class="container has-text-centered">
  <div class="content has-text-justified">
    <h3 class="title is-4">Animation</h3>
    </div>
  <video muted controls autoplay loop style="width: 80%; height: auto;">
    <source src="animations/ani_7.mp4" type="video/mp4">
  </video>
  <h2 style="text-align:center"><em> See the outcomes of different algorithms or control mechanisms applied to objects, demonstrating their effectiveness and impact.</em></h2>
</div>







 

    
    

 


  </section>





  
</body>


<script>
  var videos = document.getElementsByClassName("clickplay");
  for (var i = 0; i < videos.length; i++) {
    videos[i].addEventListener("click", function() {
      this.play();
    });
    videos[i].addEventListener("ended", function() {
      this.pause();
      this.currentTime = 0;
    });
  }
  
  document.querySelectorAll('.info-container').forEach(function(container) {
    container.addEventListener('mouseover', function() {
      var infoText = container.querySelector('.info-text');
      infoText.style.display = 'block';
    });
  
    container.addEventListener('mouseout', function() {
      var infoText = container.querySelector('.info-text');
      infoText.style.display = 'none';
    });
  });
</script>
</html>
